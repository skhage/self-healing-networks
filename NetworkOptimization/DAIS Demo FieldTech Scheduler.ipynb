{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df5ebb4c-1c74-415d-a5ad-e0ab036e1838",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b15b32d-eaa3-4a7b-a4d2-08c0908577b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "from pyspark.sql import Row\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "sf_sampled = spark.table(\"telco_demos.self_healing_networks.sf_towers\")\n",
    "field_technicians = spark.table(\"telco_demos.self_healing_networks.field_technicians\")\n",
    "route_data = []\n",
    "\n",
    "lons = sf_sampled.select('lon').toPandas()['lon'].tolist()\n",
    "lats = sf_sampled.select('lat').toPandas()['lat'].tolist()\n",
    "for tech in field_technicians.collect():\n",
    "    if random.randint(1, 7) <= 2:  # 2/7 chance of being off work\n",
    "        route_data.append(Row(\n",
    "            guid=tech.tech_id,\n",
    "            name=tech.name,\n",
    "            lat=None,\n",
    "            lon=None,\n",
    "            stop_number=None,\n",
    "            random_text=\"not scheduled\",\n",
    "            date=datetime.today().strftime('%Y-%m-%d'),\n",
    "        ))\n",
    "    else:\n",
    "        num_stops = random.randint(1, 15)\n",
    "        base_lat = random.choice(lats)\n",
    "        base_lon = lons[lats.index(base_lat)]\n",
    "        for stop_num in range(1, num_stops + 1):\n",
    "            route_data.append(Row(\n",
    "                guid=tech.tech_id,\n",
    "                name=tech.name,\n",
    "                lat=base_lat + random.uniform(-0.01, 0.01),\n",
    "                lon=base_lon + random.uniform(-0.01, 0.01),\n",
    "                stop_number=stop_num,\n",
    "                random_text=fake.text(max_nb_chars=50),\n",
    "                date=datetime.today().strftime('%Y-%m-%d'),\n",
    "            ))\n",
    "\n",
    "routes_df = spark.createDataFrame(route_data)\n",
    "routes_df.write.mode(\"append\").saveAsTable(\"telco_demos.self_healing_networks.fieldtech_route\")\n",
    "display(routes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9146ea37-da30-4463-8659-e77fd4ed3e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DAIS Demo FieldTech Scheduler",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
